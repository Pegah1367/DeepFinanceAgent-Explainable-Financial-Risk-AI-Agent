{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# مسیر فایل\n",
        "file_path = \"/content/concepts.json\"\n",
        "\n",
        "# 1. خواندن فایل\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    concepts = json.load(f)\n",
        "\n",
        "# 2. اطمینان از وجود feature_to_concept\n",
        "if \"feature_to_concept\" not in concepts:\n",
        "    concepts[\"feature_to_concept\"] = {}\n",
        "\n",
        "# 3. افزودن age\n",
        "concepts[\"feature_to_concept\"][\"age\"] = \"Age\"\n",
        "\n",
        "# 4. ذخیره مجدد فایل\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(concepts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"✔ 'age': 'Age' successfully added to feature_to_concept\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PznqE5tJ6yZf",
        "outputId": "e9566a51-bda1-47c5-dd27-ab315327489f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ 'age': 'Age' successfully added to feature_to_concept\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concepts[\"feature_to_concept\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd8qzyIk-3hm",
        "outputId": "8c6cd2eb-025b-4164-d90d-42dcb0a04abd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'Id',\n",
              " 'status': 'Status',\n",
              " 'credit_score': 'CreditScore',\n",
              " 'ltv': 'LTV',\n",
              " 'income': 'Income',\n",
              " 'loan_amount': 'LoanAmount',\n",
              " 'rate_of_interest': 'InterestRate',\n",
              " 'dtir1': 'DTIR1',\n",
              " 'credit_worthiness': 'CreditWorthiness',\n",
              " 'loan_type': 'LoanType',\n",
              " 'loan_purpose': 'LoanPurpose',\n",
              " 'property_value': 'PropertyValue',\n",
              " 'region': 'Region',\n",
              " 'year': 'Year',\n",
              " 'interest_rate_spread': 'InterestRateSpread',\n",
              " 'upfront_charges': 'UpfrontCharges',\n",
              " 'term': 'Term',\n",
              " 'loan_limit': 'LoanLimit',\n",
              " 'gender': 'Gender',\n",
              " 'approv_in_adv': 'ApprovInAdv',\n",
              " 'open_credit': 'OpenCredit',\n",
              " 'business_or_commercial': 'BusinessOrCommercial',\n",
              " 'age': 'Age',\n",
              " 'dti': 'DebtToIncomeRatio'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain langchain-community langchain-text-splitters faiss-cpu sentence-transformers joblib\n"
      ],
      "metadata": {
        "id": "fgeFgqdF_BLY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "CSV_PATH = \"/content/Loan_Default_Cleaned.csv\"\n",
        "CONCEPTS_PATH = \"/content/concepts.json\"\n",
        "DICT_PATH = \"/content/data_dictionary.csv\"\n",
        "SCHEMA_PATH = \"/content/response_schema.md\"\n",
        "META_PATH = \"/content/model_meta.json\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "concepts = json.load(open(CONCEPTS_PATH, \"r\", encoding=\"utf-8\"))\n",
        "data_dict = pd.read_csv(DICT_PATH)\n",
        "schema_md = open(SCHEMA_PATH, \"r\", encoding=\"utf-8\").read()\n",
        "model_meta = json.load(open(META_PATH, \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "print(\"df shape:\", df.shape)\n",
        "print(\"df columns:\", len(df.columns))\n",
        "print(\"concept keys:\", list(concepts.keys()))\n",
        "print(\"schema lines:\", len(schema_md.splitlines()))\n",
        "print(\"model_meta:\", model_meta)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "8-Koi_xkBy8W",
        "outputId": "6ad6d0f6-879e-4940-aa2f-ba8d76e89201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df shape: (120488, 34)\n",
            "df columns: 34\n",
            "concept keys: ['risk_buckets', 'offer_types', 'conditions_catalog', 'feature_to_concept', 'policy_topics', 'DTIR1', 'DebtToIncomeRatio', 'LTV', 'CreditScore', 'Income', 'LoanAmount', 'Age']\n",
            "schema lines: 29\n",
            "model_meta: {'sklearn': '1.8.0'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id  year loan_limit             gender approv_in_adv loan_type  \\\n",
              "0  24890  2019         cf  sex not available         nopre     type1   \n",
              "1  24891  2019         cf               male         nopre     type2   \n",
              "2  24892  2019         cf               male           pre     type1   \n",
              "3  24893  2019         cf               male         nopre     type1   \n",
              "4  24894  2019         cf              joint           pre     type1   \n",
              "\n",
              "  loan_purpose credit_worthiness open_credit business_or_commercial  ...  \\\n",
              "0           p1                l1        nopc                  nob/c  ...   \n",
              "1           p1                l1        nopc                    b/c  ...   \n",
              "2           p1                l1        nopc                  nob/c  ...   \n",
              "3           p4                l1        nopc                  nob/c  ...   \n",
              "4           p1                l1        nopc                  nob/c  ...   \n",
              "\n",
              "   credit_type  credit_score  co-applicant_credit_type    age  \\\n",
              "0          exp         758.0                       cib  25-34   \n",
              "1         equi         552.0                       exp  55-64   \n",
              "2          exp         834.0                       cib  35-44   \n",
              "3          exp         587.0                       cib  45-54   \n",
              "4         crif         602.0                       exp  25-34   \n",
              "\n",
              "   submission_of_application        ltv region security_type  status dtir1  \n",
              "0                    to_inst  98.728814  south        direct     1.0  45.0  \n",
              "1                    to_inst  75.152439  north        direct     1.0  39.0  \n",
              "2                    to_inst  80.019685  south        direct     0.0  46.0  \n",
              "3                   not_inst  69.376900  north        direct     0.0  42.0  \n",
              "4                   not_inst  91.886544  north        direct     0.0  39.0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdc1e054-fef4-4ee2-b7ec-c1faaeac2b58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>loan_limit</th>\n",
              "      <th>gender</th>\n",
              "      <th>approv_in_adv</th>\n",
              "      <th>loan_type</th>\n",
              "      <th>loan_purpose</th>\n",
              "      <th>credit_worthiness</th>\n",
              "      <th>open_credit</th>\n",
              "      <th>business_or_commercial</th>\n",
              "      <th>...</th>\n",
              "      <th>credit_type</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>co-applicant_credit_type</th>\n",
              "      <th>age</th>\n",
              "      <th>submission_of_application</th>\n",
              "      <th>ltv</th>\n",
              "      <th>region</th>\n",
              "      <th>security_type</th>\n",
              "      <th>status</th>\n",
              "      <th>dtir1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24890</td>\n",
              "      <td>2019</td>\n",
              "      <td>cf</td>\n",
              "      <td>sex not available</td>\n",
              "      <td>nopre</td>\n",
              "      <td>type1</td>\n",
              "      <td>p1</td>\n",
              "      <td>l1</td>\n",
              "      <td>nopc</td>\n",
              "      <td>nob/c</td>\n",
              "      <td>...</td>\n",
              "      <td>exp</td>\n",
              "      <td>758.0</td>\n",
              "      <td>cib</td>\n",
              "      <td>25-34</td>\n",
              "      <td>to_inst</td>\n",
              "      <td>98.728814</td>\n",
              "      <td>south</td>\n",
              "      <td>direct</td>\n",
              "      <td>1.0</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24891</td>\n",
              "      <td>2019</td>\n",
              "      <td>cf</td>\n",
              "      <td>male</td>\n",
              "      <td>nopre</td>\n",
              "      <td>type2</td>\n",
              "      <td>p1</td>\n",
              "      <td>l1</td>\n",
              "      <td>nopc</td>\n",
              "      <td>b/c</td>\n",
              "      <td>...</td>\n",
              "      <td>equi</td>\n",
              "      <td>552.0</td>\n",
              "      <td>exp</td>\n",
              "      <td>55-64</td>\n",
              "      <td>to_inst</td>\n",
              "      <td>75.152439</td>\n",
              "      <td>north</td>\n",
              "      <td>direct</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24892</td>\n",
              "      <td>2019</td>\n",
              "      <td>cf</td>\n",
              "      <td>male</td>\n",
              "      <td>pre</td>\n",
              "      <td>type1</td>\n",
              "      <td>p1</td>\n",
              "      <td>l1</td>\n",
              "      <td>nopc</td>\n",
              "      <td>nob/c</td>\n",
              "      <td>...</td>\n",
              "      <td>exp</td>\n",
              "      <td>834.0</td>\n",
              "      <td>cib</td>\n",
              "      <td>35-44</td>\n",
              "      <td>to_inst</td>\n",
              "      <td>80.019685</td>\n",
              "      <td>south</td>\n",
              "      <td>direct</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24893</td>\n",
              "      <td>2019</td>\n",
              "      <td>cf</td>\n",
              "      <td>male</td>\n",
              "      <td>nopre</td>\n",
              "      <td>type1</td>\n",
              "      <td>p4</td>\n",
              "      <td>l1</td>\n",
              "      <td>nopc</td>\n",
              "      <td>nob/c</td>\n",
              "      <td>...</td>\n",
              "      <td>exp</td>\n",
              "      <td>587.0</td>\n",
              "      <td>cib</td>\n",
              "      <td>45-54</td>\n",
              "      <td>not_inst</td>\n",
              "      <td>69.376900</td>\n",
              "      <td>north</td>\n",
              "      <td>direct</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24894</td>\n",
              "      <td>2019</td>\n",
              "      <td>cf</td>\n",
              "      <td>joint</td>\n",
              "      <td>pre</td>\n",
              "      <td>type1</td>\n",
              "      <td>p1</td>\n",
              "      <td>l1</td>\n",
              "      <td>nopc</td>\n",
              "      <td>nob/c</td>\n",
              "      <td>...</td>\n",
              "      <td>crif</td>\n",
              "      <td>602.0</td>\n",
              "      <td>exp</td>\n",
              "      <td>25-34</td>\n",
              "      <td>not_inst</td>\n",
              "      <td>91.886544</td>\n",
              "      <td>north</td>\n",
              "      <td>direct</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdc1e054-fef4-4ee2-b7ec-c1faaeac2b58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdc1e054-fef4-4ee2-b7ec-c1faaeac2b58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdc1e054-fef4-4ee2-b7ec-c1faaeac2b58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-747e0e81-370f-46d6-8be1-77d42c7b1bd7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-747e0e81-370f-46d6-8be1-77d42c7b1bd7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-747e0e81-370f-46d6-8be1-77d42c7b1bd7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = \"status\"\n",
        "\n",
        "# 1) target to int\n",
        "df[TARGET] = df[TARGET].astype(int)\n",
        "\n",
        "# 2) required columns for your agent\n",
        "REQUIRED_FOR_AGENT = [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"age\"]\n",
        "missing = [c for c in REQUIRED_FOR_AGENT if c not in df.columns]\n",
        "print(\"Missing required columns:\", missing)\n",
        "\n",
        "# 3) quick type normalization for numeric columns\n",
        "for c in [\"income\",\"credit_score\",\"loan_amount\",\"ltv\",\"dtir1\",\"age\"]:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "print(df[REQUIRED_FOR_AGENT + [TARGET]].isna().mean().sort_values(ascending=False).head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4IIoZlZB2tO",
        "outputId": "d6243acb-e864-45d3-c455-a3d10fd7fa5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing required columns: []\n",
            "age             1.0\n",
            "credit_score    0.0\n",
            "income          0.0\n",
            "loan_amount     0.0\n",
            "ltv             0.0\n",
            "dtir1           0.0\n",
            "status          0.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET].astype(int)\n",
        "\n",
        "num_cols = X.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "num_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_pipe, num_cols),\n",
        "        (\"cat\", cat_pipe, cat_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=2000, n_jobs=None)\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", model)\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "p = pipe.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, p)\n",
        "\n",
        "print(\"ROC-AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMKO4BXvCAth",
        "outputId": "43d96c0b-59a5-488e-ccf6-e6b3fd3b5ce3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['age']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['age']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC: 0.8604012411633009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, json\n",
        "\n",
        "joblib.dump(pipe, \"risk_model.joblib\")\n",
        "\n",
        "artifact = {\n",
        "    \"target\": TARGET,\n",
        "    \"input_columns\": list(X.columns),\n",
        "    \"required_for_agent\": REQUIRED_FOR_AGENT,\n",
        "    \"risk_thresholds\": {\"low\": 0.30, \"high\": 0.70},\n",
        "}\n",
        "json.dump(artifact, open(\"agent_artifacts.json\",\"w\"), indent=2)\n",
        "\n",
        "print(\"Saved: risk_model.joblib, agent_artifacts.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ajQwoICKDp",
        "outputId": "2c23d08e-b40f-482a-9c5d-1405175fe440"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: risk_model.joblib, agent_artifacts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=json.dumps(concepts, ensure_ascii=False, indent=2),\n",
        "        metadata={\"source\":\"concepts_json\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=schema_md,\n",
        "        metadata={\"source\":\"response_schema\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=data_dict.to_csv(index=False),\n",
        "        metadata={\"source\":\"data_dictionary\"}\n",
        "    ),\n",
        "]\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=120,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "print(\"docs:\", len(docs), \"chunks:\", len(chunks))\n",
        "print(chunks[0].metadata, chunks[0].page_content[:200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu6leCMzCj_P",
        "outputId": "386295d5-fa68-406f-dd10-fdf5c7251231"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docs: 3 chunks: 10\n",
            "{'source': 'concepts_json'} {\n",
            "  \"risk_buckets\": [\n",
            "    \"Low\",\n",
            "    \"Medium\",\n",
            "    \"High\"\n",
            "  ],\n",
            "  \"offer_types\": [\n",
            "    \"Approve\",\n",
            "    \"Approve_with_conditions\",\n",
            "    \"Decline\",\n",
            "    \"ManualReview\"\n",
            "  ],\n",
            "  \"conditions_catalog\": [\n",
            "    \"Re\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vs = FAISS.from_documents(chunks, emb)\n",
        "retriever = vs.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Save index for later (Streamlit)\n",
        "vs.save_local(\"faiss_index\")\n",
        "print(\"Saved FAISS index to: faiss_index/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVamm5dkDFSZ",
        "outputId": "78aba28c-a90c-446d-e38a-d27a984956db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1528992528.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved FAISS index to: faiss_index/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_fetch(query: str, k: int = 4):\n",
        "    # The retriever object is showing an AttributeError for get_relevant_documents.\n",
        "    # Using the direct similarity_search method from the FAISS vector store as an alternative.\n",
        "    return vs.similarity_search(query, k=k)\n",
        "\n",
        "hits = rag_fetch(\"What is DTIR1 and how is it used?\", k=4)\n",
        "[(h.metadata.get(\"source\"), h.page_content[:120].replace(\"\\n\", \" \")) for h in hits]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEc-hhNVDMTA",
        "outputId": "42717ab9-5b62-4584-eeda-9026bd8c407f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('concepts_json',\n",
              "  '\"pricing\",     \"manual_review_rules\"   ],   \"DTIR1\": {     \"name\": \"DTIR1 (Debt-to-Income Ratio Tier 1)\",     \"descripti'),\n",
              " ('concepts_json',\n",
              "  '\"used_in_risk\": true   },   \"LTV\": {     \"name\": \"Loan-to-Value Ratio (LTV)\",     \"description\": \"LTV represents the rat'),\n",
              " ('response_schema',\n",
              "  '# Chatbot Output Schema (Always Return This Structure)  ## 1) Risk_Assessment - risk_bucket: Low | Medium | High - confi'),\n",
              " ('concepts_json',\n",
              "  '\"loan_purpose\": \"LoanPurpose\",     \"property_value\": \"PropertyValue\",     \"region\": \"Region\",     \"year\": \"Year\",     \"i')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Final code***"
      ],
      "metadata": {
        "id": "mpgLrArC7oii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y numpy scipy scikit-learn\n",
        "!pip -q install \"numpy<2.1\" \"scipy<1.12\" \"scikit-learn<1.5\"\n",
        "!pip -q install -U langchain langchain-community langchain-text-splitters faiss-cpu sentence-transformers transformers accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyI_ZObFJFcH",
        "outputId": "1c3e5969-5935-4b2e-cb4b-bfb50a283ebd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "mapclassify 2.10.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "spopt 0.7.0 requires scipy>=1.12.0, but you have scipy 1.11.4 which is incompatible.\n",
            "giddy 2.3.8 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "esda 2.8.0 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "inequality 1.1.2 requires scipy>=1.12, but you have scipy 1.11.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "access 1.1.10.post3 requires scipy>=1.14.1, but you have scipy 1.11.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy, scipy, sklearn\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqq2LCWpJJbn",
        "outputId": "6b314503-d229-4a3c-f40d-3648bc6caf79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 1.26.4\n",
            "scipy: 1.11.4\n",
            "sklearn: 1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from typing import Dict, Any, List, Optional, Tuple\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
      ],
      "metadata": {
        "id": "S-5FS7RvJSaY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy, scipy, sklearn\n",
        "print(\"numpy:\", numpy.__version__)\n",
        "print(\"scipy:\", scipy.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"torch:\", torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRMmY3GLJ0hK",
        "outputId": "6d861e06-3f30-4a61-e5e8-30ec48c9efe4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 1.26.4\n",
            "scipy: 1.11.4\n",
            "sklearn: 1.4.2\n",
            "torch: 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 1) Paths ----------\n",
        "CSV_PATH       = \"/content/Loan_Default_Cleaned.csv\"\n",
        "CONCEPTS_PATH  = \"/content/concepts.json\"\n",
        "DICT_PATH      = \"/content/data_dictionary.csv\"       # optional (ok if missing)\n",
        "SCHEMA_PATH    = \"/content/response_schema.md\"\n",
        "MODEL_PATH     = \"/content/risk_model.joblib\"\n",
        "ART_PATH       = \"/content/agent_artifacts.json\"\n",
        "FAISS_DIR      = \"/content/faiss_index\"\n",
        "\n",
        "TARGET_COL     = \"Status\"  # change if your dataset uses 'status' or another label\n"
      ],
      "metadata": {
        "id": "IeLCJ0Sh7nOa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a utility layer for input cleaning and safety.\n",
        "\n",
        "It runs before the model, rules, or RAG logic and ensures that:\n",
        "\n",
        "Files are read safely without crashing if they are missing\n",
        "\n",
        "User inputs like \"$3,500\", \"45%\", or \"1,200\" are converted into valid numbers\n",
        "\n",
        "Values are kept within acceptable ranges\n",
        "\n",
        "Age values written as text or ranges (e.g., \"25–34\") are converted into usable numeric values\n",
        "\n",
        "Its role in the system:\n",
        "\n",
        "Raw user input\n",
        "→ Input normalization & safety (this code)\n",
        "→ Feature engineering / rules\n",
        "→ Model & RAG explanation\n",
        "→ Reliable output\n",
        "\n",
        "\n",
        "Without this layer, real human input would easily break the system or lead to incorrect decisions."
      ],
      "metadata": {
        "id": "q_lQS7VlSAAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 2) Small utilities ----------\n",
        "def _safe_read_text(path: str) -> str:\n",
        "    if not os.path.exists(path):\n",
        "        return \"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def _safe_read_json(path: str) -> Dict[str, Any]:\n",
        "    if not os.path.exists(path):\n",
        "        return {}\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def _to_number(x: Any) -> Optional[float]:\n",
        "    if x is None:\n",
        "        return None\n",
        "    s = str(x).strip().replace(\",\", \"\")\n",
        "    if s == \"\":\n",
        "        return None\n",
        "\n",
        "    # allow $, %\n",
        "    s = s.replace(\"$\", \"\").replace(\"%\", \"\")\n",
        "\n",
        "    try:\n",
        "        return float(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _clamp(v: float, lo: float, hi: float) -> float:\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def age_to_num(x: Any) -> Optional[float]:\n",
        "    \"\"\"\n",
        "    Accepts:\n",
        "      - \"25-34\", \"25 to 34 years\" -> average\n",
        "      - \"35\", \"35 years\"          -> 35\n",
        "    \"\"\"\n",
        "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
        "        return None\n",
        "\n",
        "    s = str(x).strip().lower()\n",
        "\n",
        "    # range: 25-34 OR 25 to 34\n",
        "    m = re.search(r\"(\\d{1,3})\\s*(?:-|to)\\s*(\\d{1,3})\", s)\n",
        "    if m:\n",
        "        a, b = int(m.group(1)), int(m.group(2))\n",
        "        return (a + b) / 2.0\n",
        "\n",
        "    # single number\n",
        "    m = re.search(r\"(\\d{1,3})\", s)\n",
        "    if m:\n",
        "        return float(m.group(1))\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "JtnFngtC7nKo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 3) Load data + minimal cleaning ----------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Normalize target name\n",
        "if TARGET_COL not in df.columns:\n",
        "    if \"status\" in df.columns:\n",
        "        TARGET_COL = \"status\"\n",
        "    elif \"Status\" in df.columns:\n",
        "        TARGET_COL = \"Status\"\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"TARGET_COL '{TARGET_COL}' not found. Available columns: {list(df.columns)[:30]} ...\"\n",
        "        )\n",
        "\n",
        "# Ensure target is numeric\n",
        "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors=\"coerce\")\n",
        "df = df.dropna(subset=[TARGET_COL])\n",
        "\n",
        "# Cast to int\n",
        "df[TARGET_COL] = df[TARGET_COL].astype(int)\n",
        "\n",
        "# Normalize target to 0/1 (handles -1/1, 1/2, etc.)\n",
        "unique_y = sorted(df[TARGET_COL].unique().tolist())\n",
        "if unique_y == [-1, 1]:\n",
        "    df[TARGET_COL] = (df[TARGET_COL] == 1).astype(int)\n",
        "elif unique_y == [1, 2]:\n",
        "    df[TARGET_COL] = (df[TARGET_COL] == 2).astype(int)\n",
        "else:\n",
        "    # If already 0/1, keep; otherwise leave as-is (but warn)\n",
        "    if set(unique_y) != {0, 1} and len(unique_y) <= 5:\n",
        "        print(f\"Warning: unusual target values: {unique_y}\")\n",
        "\n",
        "# If you have an 'age' column, convert it; otherwise ignore\n",
        "if \"age\" in df.columns:\n",
        "    df[\"age\"] = df[\"age\"].apply(age_to_num).astype(\"float64\")\n",
        "\n",
        "print(\"Data shape:\", df.shape)\n",
        "print(\"Target:\", TARGET_COL, \"pos rate:\", float(df[TARGET_COL].mean()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkHg6AGbF7mv",
        "outputId": "04a698cc-3737-4834-d3f2-617acb1d84fa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (120488, 34)\n",
            "Target: status pos rate: 0.2465390744306487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 4) Train (or load) risk model ----------\n",
        "def train_or_load_model(df: pd.DataFrame, target: str) -> Tuple[Pipeline, Dict[str, Any]]:\n",
        "    if os.path.exists(MODEL_PATH) and os.path.exists(ART_PATH):\n",
        "        pipe = joblib.load(MODEL_PATH)\n",
        "        art = _safe_read_json(ART_PATH)\n",
        "        return pipe, art\n",
        "\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target].astype(int)\n",
        "\n",
        "    # Robust numeric detection\n",
        "    num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    num_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "    cat_pipe = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", num_pipe, num_cols),\n",
        "            (\"cat\", cat_pipe, cat_cols),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model = LogisticRegression(max_iter=2000)\n",
        "\n",
        "    pipe = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    input_columns = list(X.columns)\n",
        "\n",
        "    # REQUIRED fields for chatbot dialog (minimal, but reliable)\n",
        "    candidates = [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"dti\", \"age\"]\n",
        "    input_cols_lower = {c.lower(): c for c in input_columns}\n",
        "\n",
        "    required_for_agent = []\n",
        "    for c in candidates:\n",
        "        if c in input_cols_lower:\n",
        "            required_for_agent.append(input_cols_lower[c])\n",
        "\n",
        "    # Store BOTH: full model columns + minimal chatbot fields (canonical names)\n",
        "    risk_thresholds = {\"low\": 0.30, \"high\": 0.70}\n",
        "\n",
        "    art = {\n",
        "        \"target\": target,\n",
        "        \"input_columns\": input_columns,                 # columns used by trained model\n",
        "        \"required_for_agent\": candidates,               # canonical names the agent expects\n",
        "        \"column_name_map\": input_cols_lower,            # helps map canonical->actual df columns\n",
        "        \"risk_thresholds\": risk_thresholds,\n",
        "    }\n",
        "\n",
        "    joblib.dump(pipe, MODEL_PATH)\n",
        "    with open(ART_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(art, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"Saved:\", MODEL_PATH, ART_PATH)\n",
        "    return pipe, art\n",
        "\n",
        "\n",
        "pipe, art = train_or_load_model(df, TARGET_COL)\n",
        "\n",
        "INPUT_COLS: List[str] = art[\"input_columns\"]\n",
        "REQ: List[str] = art[\"required_for_agent\"]          # canonical keys\n",
        "COLMAP: Dict[str, str] = art.get(\"column_name_map\", {})\n",
        "TH: Dict[str, float] = art[\"risk_thresholds\"]\n",
        "\n",
        "print(\"Required fields (canonical):\", REQ)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "murJxKK6F8jX",
        "outputId": "9364948e-5338-4f6b-aa3f-d79a6f066b78"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required fields (canonical): ['income', 'credit_score', 'loan_amount', 'ltv', 'dtir1', 'age']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree(\"/content/faiss_index\", ignore_errors=True)\n",
        "print(\"FAISS index removed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6d4xTvIc25Y",
        "outputId": "32b09715-8905-4047-ac65-eddf81204b7d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def concepts_to_documents(concepts: dict) -> List[Document]:\n",
        "    docs = []\n",
        "\n",
        "    for key, val in concepts.items():\n",
        "        # فقط مفاهیم واقعی، نه mappingها\n",
        "        if not isinstance(val, dict):\n",
        "            continue\n",
        "        if \"description\" not in val:\n",
        "            continue\n",
        "\n",
        "        text = f\"\"\"\n",
        "Concept: {key}\n",
        "Name: {val.get('name', key)}\n",
        "Description: {val.get('description', '')}\n",
        "Used in risk model: {val.get('used_in_risk', False)}\n",
        "Related features: {\", \".join(val.get('related_features', []))}\n",
        "\"\"\".strip()\n",
        "\n",
        "        docs.append(\n",
        "            Document(\n",
        "                page_content=text,\n",
        "                metadata={\n",
        "                    \"source\": \"concepts.json\",\n",
        "                    \"concept\": key\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "QcdFrdXbef1Y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 5) Build / load RAG index ----------\n",
        "concepts = _safe_read_json(CONCEPTS_PATH)\n",
        "schema_md = _safe_read_text(SCHEMA_PATH)\n",
        "\n",
        "dict_text = \"\"\n",
        "if os.path.exists(DICT_PATH):\n",
        "    try:\n",
        "        dict_df = pd.read_csv(DICT_PATH)\n",
        "        dict_text = dict_df.head(200).to_csv(index=False)\n",
        "    except Exception:\n",
        "        dict_text = _safe_read_text(DICT_PATH)\n",
        "\n",
        "def _needs_rebuild(index_dir: str, watched_files: List[str]) -> bool:\n",
        "    \"\"\"Rebuild if index missing OR any watched file is newer than index.\"\"\"\n",
        "    if not os.path.isdir(index_dir):\n",
        "        return True\n",
        "    try:\n",
        "        index_mtime = os.path.getmtime(index_dir)\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "    for p in watched_files:\n",
        "        if os.path.exists(p):\n",
        "            try:\n",
        "                if os.path.getmtime(p) > index_mtime:\n",
        "                    return True\n",
        "            except Exception:\n",
        "                pass\n",
        "    return False\n",
        "\n",
        "def build_or_load_faiss(force_rebuild: bool = False) -> FAISS:\n",
        "    emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    watched = [CONCEPTS_PATH, SCHEMA_PATH, DICT_PATH]\n",
        "\n",
        "    # Load if OK\n",
        "    if not force_rebuild and not _needs_rebuild(FAISS_DIR, watched):\n",
        "        try:\n",
        "            return FAISS.load_local(\n",
        "                FAISS_DIR,\n",
        "                emb,\n",
        "                allow_dangerous_deserialization=True\n",
        "            )\n",
        "        except Exception:\n",
        "            pass  # rebuild\n",
        "\n",
        "    # Build docs\n",
        "    docs: List[Document] = []\n",
        "\n",
        "    # Concepts\n",
        "    if isinstance(concepts, dict) and concepts:\n",
        "        docs.extend(concepts_to_documents(concepts))\n",
        "    else:\n",
        "        docs.append(Document(page_content=\"No concepts loaded.\", metadata={\"source\": \"concepts.json\"}))\n",
        "\n",
        "    # Schema (useful for response formatting/policy)\n",
        "    if schema_md and schema_md.strip():\n",
        "        docs.append(Document(page_content=schema_md, metadata={\"source\": \"response_schema.md\"}))\n",
        "\n",
        "    # OPTIONAL: data dictionary\n",
        "    # If you keep it, name the metadata consistently so later filters work.\n",
        "    # If you don't need it for answering, comment this out.\n",
        "    if dict_text and dict_text.strip():\n",
        "        docs.append(Document(page_content=dict_text, metadata={\"source\": \"data_dictionary\"}))\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=120)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "\n",
        "    vs = FAISS.from_documents(chunks, emb)\n",
        "    os.makedirs(FAISS_DIR, exist_ok=True)\n",
        "    vs.save_local(FAISS_DIR)\n",
        "\n",
        "    print(\"RAG built. Chunks:\", len(chunks))\n",
        "    return vs\n",
        "\n",
        "vs = build_or_load_faiss(force_rebuild=False)\n",
        "\n",
        "def rag_fetch(query: str, k: int = 4, allowed_sources: Optional[set] = None) -> List[Document]:\n",
        "    docs = vs.similarity_search(query, k=k)\n",
        "    if allowed_sources:\n",
        "        docs = [d for d in docs if d.metadata.get(\"source\") in allowed_sources]\n",
        "    return docs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZYB1R3zGBIB",
        "outputId": "4c9fa627-1e21-498d-bfde-30012e98f956"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG built. Chunks: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the system’s “speaking brain”: it loads the FLAN-T5 language model and generates clear, human-readable text responses from a given prompt."
      ],
      "metadata": {
        "id": "KI1grcOlTu0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 6) Load LLM (FLAN-T5) ----------\n",
        "LLM_MODEL = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
        "llm = AutoModelForSeq2SeqLM.from_pretrained(LLM_MODEL)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "llm = llm.to(device)\n",
        "\n",
        "print(\"LLM loaded:\", LLM_MODEL, \"on\", device)\n",
        "\n",
        "def llm_generate(prompt: str, max_new_tokens: int = 180, deterministic: bool = True) -> str:\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if deterministic:\n",
        "            out = llm.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=False,\n",
        "                num_beams=1\n",
        "            )\n",
        "        else:\n",
        "            out = llm.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                num_beams=1\n",
        "            )\n",
        "\n",
        "    return tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL1heFSdGE2P",
        "outputId": "4240f4c8-b2f0-4716-a955-cfeb91fff669"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM loaded: google/flan-t5-base on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code decides what the user is trying to do before taking any action.\n",
        "\n",
        "It routes each message into one of two intents:\n",
        "\n",
        "concept → the user is asking for definitions, explanations, policies, or schemas\n",
        "\n",
        "application → the user is providing numbers or asking for a loan decision\n",
        "\n",
        "The logic is rule-first:\n",
        "\n",
        "If the message looks like code → treat it as concept\n",
        "\n",
        "If it contains two or more numbers → treat it as application\n",
        "\n",
        "If it contains concept-related keywords → treat it as concept\n",
        "\n",
        "Otherwise, default to concept (safer and avoids unnecessary data collection)\n",
        "\n",
        "An LLM-based classifier exists as a fallback, but the system prefers rules to stay fast, stable, and predictable."
      ],
      "metadata": {
        "id": "PbREjfXGUR_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 7) Intent routing (RULE-FIRST, robust) ----------\n",
        "\n",
        "# explicit application triggers\n",
        "APPLICATION_KEYWORDS = [\n",
        "    \"apply for a loan\", \"loan application\", \"i want to apply\", \"apply loan\",\n",
        "    \"get a loan\", \"loan request\", \"i want a loan\", \"need a loan\", \"mortgage application\",\n",
        "]\n",
        "\n",
        "# definition / concept triggers (but must be loan-domain)\n",
        "DEF_PREFIX = (\"what is\", \"what does\", \"define\", \"explain\", \"meaning of\")\n",
        "\n",
        "# loan-domain tokens (guard concepts + help detect application)\n",
        "LOAN_TOKENS = {\n",
        "    \"loan\", \"mortgage\", \"credit\", \"risk\", \"default\",\n",
        "    \"ltv\", \"dti\", \"dtir\", \"dtir1\", \"income\", \"credit score\", \"loan amount\", \"age\",\n",
        "}\n",
        "\n",
        "# if user mentions these, it's very likely an application message (even one-by-one)\n",
        "FIELD_TOKENS = {\n",
        "    \"income\", \"salary\",\n",
        "    \"credit score\", \"credit_score\", \"score\",\n",
        "    \"loan amount\", \"loan_amount\", \"amount\", \"borrow\",\n",
        "    \"ltv\", \"dti\", \"dtir\", \"dtir1\",\n",
        "    \"age\", \"years old\", \"yo\",\n",
        "}\n",
        "\n",
        "def looks_like_code(t: str) -> bool:\n",
        "    t = (t or \"\").strip().lower()\n",
        "    return (\n",
        "        \"import \" in t or \"from \" in t or \"def \" in t or \"class \" in t\n",
        "        or t.startswith(\"!pip\") or \"```\" in t\n",
        "    )\n",
        "\n",
        "def _has_any(text: str, terms: set[str]) -> bool:\n",
        "    t = (text or \"\").lower()\n",
        "    return any(term in t for term in terms)\n",
        "\n",
        "def _starts_with_any(text: str, prefixes: tuple[str, ...]) -> bool:\n",
        "    t = (text or \"\").strip().lower()\n",
        "    return any(t.startswith(p) for p in prefixes)\n",
        "\n",
        "def classify_intent_llm(user_text: str) -> str:\n",
        "    # optional fallback; keep deterministic in llm_generate(deterministic=True)\n",
        "    prompt = f\"\"\"\n",
        "You route messages for a loan risk assistant.\n",
        "\n",
        "Return ONLY one label: concept OR application OR out_of_scope.\n",
        "\n",
        "- concept: user asks for meaning/definition/explanation of loan terms like DTI/LTV/DTIR1/credit score.\n",
        "- application: user provides applicant numbers or loan fields (income, credit score, loan amount, LTV, DTIR1, age) or asks for a decision.\n",
        "- out_of_scope: anything else.\n",
        "\n",
        "Message:\n",
        "{user_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "    y = llm_generate(prompt, max_new_tokens=8, deterministic=True).lower()\n",
        "    if \"application\" in y:\n",
        "        return \"application\"\n",
        "    if \"concept\" in y:\n",
        "        return \"concept\"\n",
        "    return \"out_of_scope\"\n",
        "\n",
        "def route_intent(user_text: str) -> str:\n",
        "    t = (user_text or \"\").strip().lower()\n",
        "    if not t:\n",
        "        return \"out_of_scope\"\n",
        "\n",
        "    # 0) code always treated as out_of_scope (or concept if you prefer), but NOT application\n",
        "    if looks_like_code(t):\n",
        "        return \"out_of_scope\"\n",
        "\n",
        "    # 1) explicit application keywords\n",
        "    if any(k in t for k in APPLICATION_KEYWORDS):\n",
        "        return \"application\"\n",
        "\n",
        "    # 2) if it mentions any loan field token -> application (supports step-by-step input)\n",
        "    #    examples: \"my income is 4500\" / \"credit score 680\" / \"ltv 75\"\n",
        "    if _has_any(t, FIELD_TOKENS):\n",
        "        return \"application\"\n",
        "\n",
        "    # 3) concept questions only if: definition prompt AND within loan domain\n",
        "    #    example: \"what does dtir1 mean?\" -> concept\n",
        "    if _starts_with_any(t, DEF_PREFIX) and _has_any(t, LOAN_TOKENS):\n",
        "        return \"concept\"\n",
        "\n",
        "    # 4) short single-term concept query: \"dtir1\" / \"ltv\" / \"credit score\"\n",
        "    if len(t.split()) <= 3 and _has_any(t, {\"dtir1\", \"dtir\", \"dti\", \"ltv\", \"credit score\"}):\n",
        "        return \"concept\"\n",
        "\n",
        "    # 5) numbers alone are NOT enough; otherwise random messages with numbers go application\n",
        "    # If you REALLY want numeric heuristic, gate it with loan domain tokens:\n",
        "    nums = re.findall(r\"\\d+(?:\\.\\d+)?\", t)\n",
        "    if len(nums) >= 2 and _has_any(t, LOAN_TOKENS):\n",
        "        return \"application\"\n",
        "\n",
        "    # 6) fallback: out_of_scope (prevents \"langchain?\" going to concept/application)\n",
        "    # If you want: return classify_intent_llm(user_text) instead.\n",
        "    return \"out_of_scope\"\n"
      ],
      "metadata": {
        "id": "1i4jO-T8GJUP"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This code extracts key loan-related numbers from free-text user input (income, credit score, loan amount, DTI, age), cleans and converts them to proper numeric values, and fixes common extraction errors so the data is ready for the risk model.\n"
      ],
      "metadata": {
        "id": "2M3n-jmKUmUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 8) Field extraction (regex, SAFE) ----------\n",
        "import re\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "def extract_fields_regex(text: str) -> Dict[str, Any]:\n",
        "    t = (text or \"\").lower()\n",
        "    out: Dict[str, Any] = {}\n",
        "\n",
        "    def pick_last_number(pattern: str, group: int) -> Optional[float]:\n",
        "        matches = list(re.finditer(pattern, t, flags=re.IGNORECASE))\n",
        "        if not matches:\n",
        "            return None\n",
        "        return _to_number(matches[-1].group(group))\n",
        "\n",
        "    # ---------- income ----------\n",
        "    out[\"income\"] = pick_last_number(\n",
        "        r\"\\b(income|monthly\\s*income|salary)\\b[^\\d]{0,40}(\\d[\\d,]*(?:\\.\\d+)?)\",\n",
        "        group=2\n",
        "    )\n",
        "\n",
        "    # ---------- credit score ----------\n",
        "    out[\"credit_score\"] = pick_last_number(\n",
        "        r\"\\b(credit\\s*score|score)\\b[^\\d]{0,40}(\\d{2,4})\",\n",
        "        group=2\n",
        "    )\n",
        "\n",
        "    # ---------- loan amount ----------\n",
        "    # CRITICAL FIX: never match \"loan\" alone\n",
        "    out[\"loan_amount\"] = pick_last_number(\n",
        "        r\"\\b(\"\n",
        "        r\"(requested\\s*)?(loan\\s*amount|loan\\s*amt|loan\\s*value|borrow(?:ed)?\\s*amount|amount\\s*requested)\"\n",
        "        r\"|amount\\s*(is|=)\"\n",
        "        r\")\\b[^\\d]{0,60}(\\d[\\d,]*(?:\\.\\d+)?)\",\n",
        "        group=5\n",
        "    )\n",
        "\n",
        "    # ---------- LTV ----------\n",
        "    out[\"ltv\"] = pick_last_number(\n",
        "        r\"\\bltv\\b[^\\d]{0,40}(\\d[\\d,]*(?:\\.\\d+)?)\\s*%?\",\n",
        "        group=1\n",
        "    )\n",
        "\n",
        "    # ---------- DTIR1 ----------\n",
        "    out[\"dtir1\"] = pick_last_number(\n",
        "        r\"\\bdtir1\\b[^\\d]{0,40}(\\d[\\d,]*(?:\\.\\d+)?)\\s*%?\",\n",
        "        group=1\n",
        "    )\n",
        "\n",
        "    # ---------- DTI (only if dtir1 not present) ----------\n",
        "    if out.get(\"dtir1\") is None:\n",
        "        out[\"dti\"] = pick_last_number(\n",
        "            r\"\\bdti\\b[^\\d]{0,40}(\\d[\\d,]*(?:\\.\\d+)?)\\s*%?\",\n",
        "            group=1\n",
        "        )\n",
        "\n",
        "    # ---------- age ----------\n",
        "    out[\"age\"] = pick_last_number(\n",
        "        r\"\\b(age|years\\s*old|yo)\\b[^\\d]{0,40}(\\d{1,3})\",\n",
        "        group=2\n",
        "    )\n",
        "\n",
        "    # ---------- type enforcement ----------\n",
        "    if out.get(\"credit_score\") is not None:\n",
        "        out[\"credit_score\"] = int(out[\"credit_score\"])\n",
        "    if out.get(\"age\") is not None:\n",
        "        out[\"age\"] = int(out[\"age\"])\n",
        "\n",
        "    # ---------- HARD GUARD (very important) ----------\n",
        "    # Prevent loan_amount accidentally being income\n",
        "    if out.get(\"loan_amount\") and out.get(\"income\"):\n",
        "        if out[\"loan_amount\"] <= out[\"income\"]:\n",
        "            out[\"loan_amount\"] = None\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "1ivRlImFGMP3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the decision engine that turns model output into a clear loan decision.\n",
        "\n",
        "predict_default_probability\n",
        "Takes the user’s known inputs, runs them through the trained model, and returns a default probability between 0 and 1.\n",
        "\n",
        "map_prob_to_bucket\n",
        "Converts that probability into a risk bucket:\n",
        "\n",
        "Low risk\n",
        "\n",
        "Medium risk\n",
        "\n",
        "High risk\n",
        "using predefined thresholds.\n",
        "\n",
        "offer_engine\n",
        "Translates the risk bucket into a final decision:\n",
        "\n",
        "Low → Approve\n",
        "\n",
        "Medium → Approve with conditions\n",
        "\n",
        "High → Decline\n",
        "\n",
        "One-line summary:\n",
        "This code converts model probabilities into risk levels and then into a clear loan approval decision with optional conditions."
      ],
      "metadata": {
        "id": "vOx4MnrsW8Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 9) Risk + offer engine ----------\n",
        "from typing import Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "def predict_default_probability(known: Dict[str, Any]) -> float:\n",
        "    # Build a single-row dataframe with EXACT training columns\n",
        "    row = {c: known.get(c, None) for c in INPUT_COLS}\n",
        "    X_one = pd.DataFrame([row], columns=INPUT_COLS)\n",
        "\n",
        "    # Safety: some models may not expose predict_proba\n",
        "    if not hasattr(pipe, \"predict_proba\"):\n",
        "        raise RuntimeError(\"Model does not support predict_proba(). Train a classifier with probability outputs.\")\n",
        "\n",
        "    p = float(pipe.predict_proba(X_one)[:, 1][0])\n",
        "    return _clamp(p, 0.0, 1.0)\n",
        "\n",
        "def map_prob_to_bucket(p: float) -> str:\n",
        "    p = float(p)\n",
        "    if p < float(TH[\"low\"]):\n",
        "        return \"Low\"\n",
        "    if p < float(TH[\"high\"]):\n",
        "        return \"Medium\"\n",
        "    return \"High\"\n",
        "\n",
        "def offer_engine(bucket: str) -> Dict[str, Any]:\n",
        "    b = (bucket or \"\").strip().title()  # \"low\" -> \"Low\"\n",
        "    if b == \"Low\":\n",
        "        return {\"decision\": \"Approve\", \"conditions\": []}\n",
        "    if b == \"Medium\":\n",
        "        return {\n",
        "            \"decision\": \"Approve_with_conditions\",\n",
        "            \"conditions\": [\"Request additional documents\", \"Reduce loan amount\"],\n",
        "        }\n",
        "    return {\"decision\": \"Decline\", \"conditions\": []}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b57tSGH8GQfI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code finds the correct concept definition from concepts.json based on the user’s text.\n",
        "\n",
        "_normalize_key\n",
        "Cleans text by lowercasing it and removing spaces/symbols, so matching is consistent.\n",
        "\n",
        "lookup_concept_from_json\n",
        "Tries to identify which concept the user is asking about:\n",
        "\n",
        "Direct match: checks if the normalized concept name (e.g., DTIR1) appears in the user’s text and returns its definition.\n",
        "\n",
        "Fallback mapping: if no direct match is found, it uses a feature_to_concept mapping to link features (e.g., dti) to a concept and returns that definition.\n",
        "\n",
        "If nothing matches, it returns None.\n",
        "\n",
        "One-line summary:\n",
        "This code maps a user’s question to the right concept in concepts.json and returns its definition in a robust, typo-tolerant way."
      ],
      "metadata": {
        "id": "A2OdJsqBXXc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "def _normalize_key(s: str) -> str:\n",
        "    # keep only letters/numbers -> stable matching\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
        "\n",
        "def _tokenize_norm(s: str) -> set[str]:\n",
        "    # words (normalized) for boundary-like matching\n",
        "    raw_tokens = re.findall(r\"[a-z0-9]+\", str(s).lower())\n",
        "    return { _normalize_key(tok) for tok in raw_tokens if tok }\n",
        "\n",
        "def lookup_concept_from_json(user_text: str, concepts: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "    if not isinstance(concepts, dict) or not user_text:\n",
        "        return None\n",
        "\n",
        "    t_norm = _normalize_key(user_text)\n",
        "    t_tokens = _tokenize_norm(user_text)\n",
        "\n",
        "    # 1) direct hit on top-level concept objects (e.g., \"DTIR1\": {...})\n",
        "    for k, v in concepts.items():\n",
        "        if not isinstance(v, dict):\n",
        "            continue\n",
        "        if not (\"description\" in v or \"name\" in v):\n",
        "            continue\n",
        "\n",
        "        k_norm = _normalize_key(k)\n",
        "        # match by substring OR by token (handles \"dtir1?\" / \"what does dtir1 mean\")\n",
        "        if (k_norm and k_norm in t_norm) or (k_norm in t_tokens):\n",
        "            return {\"key\": k, \"data\": v}\n",
        "\n",
        "    # 2) fallback via feature_to_concept mapping (if present)\n",
        "    ftc = concepts.get(\"feature_to_concept\")\n",
        "    if isinstance(ftc, dict):\n",
        "        for feat, concept_name in ftc.items():\n",
        "            feat_norm = _normalize_key(feat)\n",
        "            if not feat_norm:\n",
        "                continue\n",
        "\n",
        "            if (feat_norm in t_norm) or (feat_norm in t_tokens):\n",
        "                # resolve mapped concept object\n",
        "                if concept_name in concepts and isinstance(concepts[concept_name], dict):\n",
        "                    return {\"key\": concept_name, \"data\": concepts[concept_name]}\n",
        "\n",
        "                # fallback object if mapping points to missing concept\n",
        "                return {\n",
        "                    \"key\": str(concept_name),\n",
        "                    \"data\": {\n",
        "                        \"name\": str(concept_name),\n",
        "                        \"description\": f\"Mapped from feature: {feat}\"\n",
        "                    }\n",
        "                }\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "bqPVTC5MkQw8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function answers loan-related concept questions by first returning an exact definition from concepts.json when available, otherwise safely retrieving relevant documents with RAG and using an LLM to generate a controlled explanation only from approved context, while rejecting out-of-scope questions."
      ],
      "metadata": {
        "id": "5YNYhUchYgLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any, List\n",
        "\n",
        "# ---------- 10) RAG answer (concept questions) ----------\n",
        "def concept_answer(user_text: str, k: int = 6) -> Dict[str, Any]:\n",
        "    q = (user_text or \"\").strip()\n",
        "    q_low = q.lower()\n",
        "\n",
        "    # 0) Direct concept lookup (best practice)\n",
        "    hit = lookup_concept_from_json(q, concepts)\n",
        "    if hit:\n",
        "        data = hit[\"data\"] or {}\n",
        "        name = data.get(\"name\", hit.get(\"key\", \"Concept\"))\n",
        "        desc = (data.get(\"description\") or \"\").strip()\n",
        "        used = data.get(\"used_in_risk\", data.get(\"used_in_model\", None))\n",
        "        rel = data.get(\"related_features\", [])\n",
        "\n",
        "        answer_lines: List[str] = []\n",
        "        answer_lines.append(f\"{name}: {desc}\" if desc else f\"{name}.\")\n",
        "        if used is not None:\n",
        "            answer_lines.append(f\"It is used in risk assessment: {bool(used)}.\")\n",
        "        if isinstance(rel, list) and rel:\n",
        "            answer_lines.append(f\"Related features: {', '.join(map(str, rel))}.\")\n",
        "\n",
        "        return {\n",
        "            \"type\": \"rag_answer\",\n",
        "            \"answer\": \" \".join(answer_lines),\n",
        "            \"sources\": [\"concepts.json\"],\n",
        "        }\n",
        "\n",
        "    # 1) Domain guard (reject out-of-scope questions)\n",
        "    # IMPORTANT: include dtir1 explicitly so \"What does DTIR1 mean?\" never gets rejected\n",
        "    LOAN_TERMS = [\n",
        "        \"loan\", \"credit\", \"ltv\", \"dti\", \"dtir\", \"dtir1\",\n",
        "        \"interest\", \"rate\", \"apr\", \"mortgage\", \"risk\", \"default\"\n",
        "    ]\n",
        "    if not any(t in q_low for t in LOAN_TERMS):\n",
        "        return {\"type\": \"rag_answer\", \"answer\": \"Not found in provided context.\", \"sources\": []}\n",
        "\n",
        "    # 2) RAG retrieval with relevance scores\n",
        "    # NOTE: FAISS scores are distances; smaller is better. 0.7 can be too strict.\n",
        "    docs_scores = vs.similarity_search_with_score(q, k=k)\n",
        "\n",
        "    # keep only reasonably relevant chunks (more forgiving threshold)\n",
        "    docs = [d for d, score in docs_scores if score is None or score < 1.2]\n",
        "\n",
        "    # 3) Block unsafe / non-explanatory sources\n",
        "    BLOCKED_SOURCES = {\"sample_data_head.csv\", \"data_dictionary\"}\n",
        "    docs = [d for d in docs if d.metadata.get(\"source\") not in BLOCKED_SOURCES]\n",
        "\n",
        "    if not docs:\n",
        "        return {\"type\": \"rag_answer\", \"answer\": \"Not found in provided context.\", \"sources\": []}\n",
        "\n",
        "    # 4) Build controlled context\n",
        "    sources = sorted(set(d.metadata.get(\"source\", \"unknown\") for d in docs))\n",
        "    context = \"\\n\\n\".join(\n",
        "        f\"[{i+1}] ({d.metadata.get('source','unknown')})\\n{d.page_content[:900]}\"\n",
        "        for i, d in enumerate(docs)\n",
        "    )\n",
        "\n",
        "    # 5) Strict prompt for LLM\n",
        "    prompt = f\"\"\"\n",
        "You are a loan-domain assistant.\n",
        "\n",
        "Answer the user's question using ONLY the CONTEXT below.\n",
        "If the answer is not present, say exactly:\n",
        "\"Not found in provided context.\"\n",
        "\n",
        "STRICT RULES:\n",
        "- Do NOT output raw data rows, CSV lines, or tables.\n",
        "- Do NOT invent definitions or values.\n",
        "- Explain concepts in clear, simple English.\n",
        "- No numbers unless they appear explicitly in the context.\n",
        "\n",
        "Write 4–8 sentences.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{q}\n",
        "\n",
        "ANSWER:\n",
        "\"\"\".strip()\n",
        "\n",
        "    ans = (llm_generate(prompt, max_new_tokens=220) or \"\").strip()\n",
        "    if not ans:\n",
        "        ans = \"Not found in provided context.\"\n",
        "\n",
        "    return {\"type\": \"rag_answer\", \"answer\": ans, \"sources\": sources}\n"
      ],
      "metadata": {
        "id": "3dAZ_rKJGUVY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS a test, each definition you add in concept , the chatbot can get it and aswers the user, if you need any update you do not need to train model just change the concept"
      ],
      "metadata": {
        "id": "05arHYjNcwfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# IMPORTANT: use the SAME path you use everywhere else\n",
        "# If your notebook uses /content/concepts.json, keep it that way.\n",
        "CONCEPTS_PATH = \"/content/concepts.json\"  # <-- unify this with your project\n",
        "\n",
        "# Load existing concepts.json (or start fresh)\n",
        "if os.path.exists(CONCEPTS_PATH):\n",
        "    with open(CONCEPTS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        concepts = json.load(f)\n",
        "else:\n",
        "    concepts = {}\n",
        "\n",
        "# -------------------------\n",
        "# Core risk concepts\n",
        "# -------------------------\n",
        "concepts[\"DTIR1\"] = {\n",
        "    \"name\": \"DTIR1 (Debt-to-Income Ratio Tier 1)\",\n",
        "    \"description\": (\n",
        "        \"DTIR1 measures the ratio of a borrower’s monthly debt obligations \"\n",
        "        \"to their gross monthly income. It is used to assess repayment capacity \"\n",
        "        \"and credit risk.\"\n",
        "    ),\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"income\", \"total_debt\"],\n",
        "}\n",
        "\n",
        "concepts[\"DebtToIncomeRatio\"] = {\n",
        "    \"name\": \"Debt-to-Income Ratio (DTI)\",\n",
        "    \"description\": (\n",
        "        \"Debt-to-Income Ratio compares total monthly debt payments \"\n",
        "        \"to gross monthly income to evaluate affordability.\"\n",
        "    ),\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"income\", \"total_debt\"],\n",
        "}\n",
        "\n",
        "concepts[\"LTV\"] = {\n",
        "    \"name\": \"Loan-to-Value Ratio (LTV)\",\n",
        "    \"description\": (\n",
        "        \"LTV represents the ratio of the loan amount to the value of the property. \"\n",
        "        \"Higher LTV values generally indicate higher lending risk.\"\n",
        "    ),\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"loan_amount\", \"property_value\"],\n",
        "}\n",
        "\n",
        "concepts[\"CreditScore\"] = {\n",
        "    \"name\": \"Credit Score\",\n",
        "    \"description\": (\n",
        "        \"A credit score is a numerical measure of a borrower’s creditworthiness, \"\n",
        "        \"based on past repayment behavior and credit history.\"\n",
        "    ),\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"credit_score\"],\n",
        "}\n",
        "\n",
        "concepts[\"Income\"] = {\n",
        "    \"name\": \"Income\",\n",
        "    \"description\": (\n",
        "        \"Income refers to the borrower’s gross periodic earnings and is a key factor \"\n",
        "        \"in assessing repayment ability.\"\n",
        "    ),\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"income\"],\n",
        "}\n",
        "\n",
        "concepts[\"LoanAmount\"] = {\n",
        "    \"name\": \"Loan Amount\",\n",
        "    \"description\": \"Loan amount is the total amount of money requested by the borrower.\",\n",
        "    \"used_in_risk\": True,\n",
        "    \"related_features\": [\"loan_amount\"],\n",
        "}\n",
        "\n",
        "concepts[\"Age\"] = {\n",
        "    \"name\": \"Borrower Age\",\n",
        "    \"description\": (\n",
        "        \"Age represents the borrower’s age at the time of application and may be \"\n",
        "        \"used as a supporting risk factor.\"\n",
        "    ),\n",
        "    \"used_in_risk\": False,\n",
        "    \"related_features\": [\"age\"],\n",
        "}\n",
        "\n",
        "# -------------------------\n",
        "# OPTIONAL: add simple aliases as top-level keys (helps direct matching)\n",
        "# -------------------------\n",
        "# These aliases make lookup succeed even if user types \"DTI\" or \"Credit Score\" etc.\n",
        "concepts[\"DTI\"] = concepts[\"DebtToIncomeRatio\"]\n",
        "concepts[\"credit score\"] = concepts[\"CreditScore\"]\n",
        "concepts[\"loan amount\"] = concepts[\"LoanAmount\"]\n",
        "\n",
        "# -------------------------\n",
        "# Feature-to-concept mapping\n",
        "# -------------------------\n",
        "if \"feature_to_concept\" not in concepts or not isinstance(concepts[\"feature_to_concept\"], dict):\n",
        "    concepts[\"feature_to_concept\"] = {}\n",
        "\n",
        "concepts[\"feature_to_concept\"].update({\n",
        "    # main\n",
        "    \"dtir1\": \"DTIR1\",\n",
        "    \"dti\": \"DebtToIncomeRatio\",\n",
        "    \"ltv\": \"LTV\",\n",
        "    \"credit_score\": \"CreditScore\",\n",
        "    \"income\": \"Income\",\n",
        "    \"loan_amount\": \"LoanAmount\",\n",
        "    \"age\": \"Age\",\n",
        "    # extra aliases users may type\n",
        "    \"creditscore\": \"CreditScore\",\n",
        "    \"credit score\": \"CreditScore\",\n",
        "    \"loanamount\": \"LoanAmount\",\n",
        "    \"loan amount\": \"LoanAmount\",\n",
        "})\n",
        "\n",
        "# Save back to concepts.json\n",
        "with open(CONCEPTS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(concepts, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✅ concepts.json updated at: {CONCEPTS_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgPq9Kr8cwHC",
        "outputId": "7bd6392b-947f-4e9f-cfce-e72c7561a395"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ concepts.json updated at: /content/concepts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 11) Human-like explanation (LLM) ----------\n",
        "def explanation_with_llm(\n",
        "    p_default: float,\n",
        "    bucket: str,\n",
        "    offer: Dict[str, Any],\n",
        "    known: Dict[str, Any],\n",
        "    rag_sources: List[str],  # kept for compatibility; not used in prompt\n",
        ") -> str:\n",
        "\n",
        "    def _clean(text: str) -> str:\n",
        "        # normalize whitespace, remove trailing junk\n",
        "        t = (text or \"\").strip()\n",
        "        # remove duplicated \"OUTPUT:\" if model repeats it\n",
        "        t = t.replace(\"OUTPUT:\", \"\").strip()\n",
        "        return t\n",
        "\n",
        "    def _count_bullets(t: str) -> int:\n",
        "        return sum(1 for ln in (t or \"\").splitlines() if ln.strip().startswith(\"- \"))\n",
        "\n",
        "    def _has_two_fields(t: str) -> bool:\n",
        "        # ensure it mentions at least 2 provided fields by name\n",
        "        # include both dtir1 and dti to be safe\n",
        "        names = [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"dti\", \"age\"]\n",
        "        t_low = (t or \"\").lower()\n",
        "        mentioned = 0\n",
        "        for n in names:\n",
        "            # only count if user actually provided it\n",
        "            if known.get(n) is not None and n in t_low:\n",
        "                mentioned += 1\n",
        "        return mentioned >= 2\n",
        "\n",
        "    def _fallback() -> str:\n",
        "        used = []\n",
        "        for k in [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"dti\", \"age\"]:\n",
        "            if known.get(k) is not None:\n",
        "                used.append(f\"{k}={known.get(k)}\")\n",
        "        used_txt = \", \".join(used[:4]) if used else \"the provided application fields\"\n",
        "\n",
        "        para = (\n",
        "            f\"Based on the provided application data ({used_txt}), the estimated default probability is {p_default:.2f}, \"\n",
        "            f\"which falls into the {bucket} risk bucket. The recommended decision is {offer.get('decision')}.\"\n",
        "        )\n",
        "        b1 = f\"- Risk bucket: {bucket} (estimated default probability: {p_default:.2f}).\"\n",
        "        b2 = f\"- Decision: {offer.get('decision')}.\"\n",
        "        conds = offer.get(\"conditions\", []) or []\n",
        "        cond_txt = \"None\" if not conds else \", \".join(map(str, conds))\n",
        "        b3 = f\"- Conditions: {cond_txt}.\"\n",
        "        return \"\\n\".join([para, b1, b2, b3])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a loan risk assistant. Write an explanation grounded ONLY in the provided fields.\n",
        "\n",
        "STRICT RULES (must follow):\n",
        "- Do NOT mention interest rate, pricing, fees, APR, or costs.\n",
        "- Do NOT invent policies, thresholds, or extra variables.\n",
        "- Use ONLY these applicant fields if present: income, credit_score, loan_amount, ltv, dtir1, dti, age.\n",
        "- Mention at least 2 of the provided applicant fields by name (e.g., credit_score, income).\n",
        "- Output format MUST be EXACTLY:\n",
        "  1 short paragraph (2–3 sentences)\n",
        "  then EXACTLY 3 bullet lines, each starting with \"- \"\n",
        "\n",
        "MODEL:\n",
        "default_probability = {p_default:.2f}\n",
        "risk_bucket = {bucket}\n",
        "decision = {offer.get(\"decision\")}\n",
        "conditions = {offer.get(\"conditions\", [])}\n",
        "\n",
        "APPLICANT:\n",
        "{json.dumps({k: known.get(k) for k in [\"income\",\"credit_score\",\"loan_amount\",\"ltv\",\"dtir1\",\"dti\",\"age\"]}, ensure_ascii=False)}\n",
        "\n",
        "OUTPUT:\n",
        "\"\"\".strip()\n",
        "\n",
        "    # Try 1\n",
        "    text = _clean(llm_generate(prompt, max_new_tokens=260))\n",
        "    ok = (_count_bullets(text) == 3) and _has_two_fields(text)\n",
        "\n",
        "    # Try 2\n",
        "    if not ok:\n",
        "        text = _clean(llm_generate(\n",
        "            prompt + \"\\nFINAL REMINDER: Output must be 1 paragraph + EXACTLY 3 bullet lines starting with '- '. Do not output anything else.\",\n",
        "            max_new_tokens=260\n",
        "        ))\n",
        "        ok = (_count_bullets(text) == 3) and _has_two_fields(text)\n",
        "\n",
        "    # Fallback\n",
        "    if not ok:\n",
        "        text = _fallback()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "mrlmbmtlGXg_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 12) Final structured JSON ----------\n",
        "def build_final_json(\n",
        "    p_default: float,\n",
        "    bucket: str,\n",
        "    offer: Dict[str, Any],\n",
        "    known: Dict[str, Any],\n",
        "    rag_sources: List[str],\n",
        "    explanation: str,\n",
        "    missing: List[str]\n",
        ") -> Dict[str, Any]:\n",
        "    confidence = _clamp(abs(p_default - 0.5) * 2.0, 0.0, 1.0)\n",
        "\n",
        "    # ---------- normalize explanation bullets ----------\n",
        "    raw_lines = [l.strip() for l in (explanation or \"\").splitlines() if l.strip()]\n",
        "    norm_lines = []\n",
        "    for l in raw_lines:\n",
        "        # normalize common bullet formats into \"- \"\n",
        "        if l.startswith(\"• \"):\n",
        "            l = \"- \" + l[2:].strip()\n",
        "        elif l.startswith(\"-\") and not l.startswith(\"- \"):\n",
        "            l = \"- \" + l[1:].strip()\n",
        "        norm_lines.append(l)\n",
        "\n",
        "    bullets = [l for l in norm_lines if l.startswith(\"- \")]\n",
        "    paragraph = \" \".join([l for l in norm_lines if not l.startswith(\"- \")]).strip()\n",
        "\n",
        "    # Guard 1: paragraph must exist\n",
        "    if not paragraph:\n",
        "        paragraph = (\n",
        "            f\"Based on the provided fields, the estimated default probability is {p_default:.2f} \"\n",
        "            f\"(risk bucket: {bucket}). The recommended decision is {offer.get('decision')}.\"\n",
        "        )\n",
        "\n",
        "    # Guard 2: bullets must be EXACTLY 3\n",
        "    conditions = offer.get(\"conditions\", [])\n",
        "    if conditions is None:\n",
        "        conditions = []\n",
        "    if not isinstance(conditions, list):\n",
        "        conditions = [str(conditions)]\n",
        "\n",
        "    if len(bullets) != 3:\n",
        "        cond_text = \"No additional conditions.\" if not conditions else \"Conditions: \" + \", \".join(map(str, conditions))\n",
        "        bullets = [\n",
        "            f\"- Risk bucket: {bucket} (estimated default probability: {p_default:.2f}).\",\n",
        "            f\"- Decision: {offer.get('decision')}.\",\n",
        "            f\"- {cond_text}\"\n",
        "        ]\n",
        "\n",
        "    # unify dti/dtir1 display\n",
        "    dtir1_val = known.get(\"dtir1\")\n",
        "    if dtir1_val is None:\n",
        "        dtir1_val = known.get(\"dti\")\n",
        "\n",
        "    # REQ safe\n",
        "    try:\n",
        "        req_fields = list(REQ)  # if REQ exists\n",
        "    except Exception:\n",
        "        req_fields = [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"age\"]\n",
        "\n",
        "    return {\n",
        "        \"Risk_Assessment\": {\n",
        "            \"risk_bucket\": bucket,\n",
        "            \"default_probability\": round(float(p_default), 4),\n",
        "            \"confidence\": round(float(confidence), 2),\n",
        "            \"short_summary\": f\"Estimated default probability is {p_default:.2f} (bucket: {bucket}).\"\n",
        "        },\n",
        "        \"Offer\": {\n",
        "            \"decision\": offer.get(\"decision\"),\n",
        "            \"proposed_terms\": {\"loan_amount\": known.get(\"loan_amount\", None)},\n",
        "            \"conditions\": conditions\n",
        "        },\n",
        "        \"Reasons_Data\": [\n",
        "            f\"default_probability={p_default:.2f}\",\n",
        "            f\"credit_score={known.get('credit_score')}\",\n",
        "            f\"income={known.get('income')}\",\n",
        "            f\"loan_amount={known.get('loan_amount')}\",\n",
        "            f\"ltv={known.get('ltv')}\",\n",
        "            f\"dtir1/dti={dtir1_val}\",\n",
        "            f\"age={known.get('age')}\",\n",
        "        ],\n",
        "        \"Evidence\": {\n",
        "            \"key_fields_used\": {k: known.get(k) for k in req_fields},\n",
        "            \"rag_sources\": sorted(set(rag_sources or []))\n",
        "        },\n",
        "        \"Next_Actions\": {\n",
        "            \"missing_fields_needed\": missing or [],\n",
        "            \"recommended_verifications_or_documents\": conditions\n",
        "        },\n",
        "        \"Explanation\": {\n",
        "            \"paragraph\": paragraph,\n",
        "            \"bullets\": bullets\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "1FMyjpBNGdap"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, List\n",
        "import re\n",
        "\n",
        "# =========================================================\n",
        "# 1) Intent routing (FINAL)\n",
        "# =========================================================\n",
        "\n",
        "APPLICATION_KEYWORDS = [\n",
        "    \"apply for a loan\",\n",
        "    \"loan application\",\n",
        "    \"i want to apply\",\n",
        "    \"apply loan\",\n",
        "    \"get a loan\",\n",
        "    \"loan request\",\n",
        "    \"i want a loan\",\n",
        "    \"need a loan\",\n",
        "    \"mortgage application\",\n",
        "]\n",
        "\n",
        "# loan-domain vocabulary\n",
        "LOAN_TERMS = {\n",
        "    \"loan\", \"credit\", \"ltv\", \"dti\", \"dtir\", \"dtir1\", \"mortgage\", \"risk\", \"default\",\n",
        "}\n",
        "\n",
        "# concept terms you explicitly support (also allow short one-word queries)\n",
        "SHORT_CONCEPT_TERMS = {\n",
        "    \"dtir1\", \"dti\", \"ltv\", \"credit score\", \"loan amount\", \"income\", \"age\",\n",
        "}\n",
        "\n",
        "# numeric field signals for application messages\n",
        "NUMERIC_SIGNALS = {\n",
        "    \"income\", \"credit score\", \"credit_score\", \"loan amount\", \"loan_amount\",\n",
        "    \"ltv\", \"dti\", \"dtir\", \"dtir1\", \"age\",\n",
        "}\n",
        "\n",
        "def _req_safe() -> List[str]:\n",
        "    try:\n",
        "        return list(REQ)  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        return [\"income\", \"credit_score\", \"loan_amount\", \"ltv\", \"dtir1\", \"age\"]\n",
        "\n",
        "def _norm_spaces(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\").strip().lower())\n",
        "\n",
        "def is_loan_domain(text: str) -> bool:\n",
        "    t = _norm_spaces(text)\n",
        "    return any(term in t for term in LOAN_TERMS) or any(term in t for term in SHORT_CONCEPT_TERMS)\n",
        "\n",
        "def is_concept_question(text: str) -> bool:\n",
        "    \"\"\"\n",
        "    Concept if:\n",
        "      - user asks definition/explanation/meaning, AND loan-domain\n",
        "      - OR user sends a short concept token alone (e.g., \"dtir1\", \"ltv\")\n",
        "    \"\"\"\n",
        "    t = _norm_spaces(text)\n",
        "    if not t:\n",
        "        return False\n",
        "\n",
        "    # direct short token query\n",
        "    if t in SHORT_CONCEPT_TERMS:\n",
        "        return True\n",
        "\n",
        "    definition_prompt = any(t.startswith(x) for x in (\"what is\", \"what does\", \"define\", \"explain\", \"meaning of\"))\n",
        "    questionish = (\"?\" in t)\n",
        "\n",
        "    # If it's definition-style AND loan domain -> concept\n",
        "    if (definition_prompt or questionish) and is_loan_domain(t) and any(tok in t for tok in SHORT_CONCEPT_TERMS.union(LOAN_TERMS)):\n",
        "        return True\n",
        "\n",
        "    # \"explain dtir1\" / \"define ltv\" variants\n",
        "    if any(x in t for x in (\"define\", \"explain\", \"meaning\")) and is_loan_domain(t):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def looks_like_application(text: str) -> bool:\n",
        "    \"\"\"\n",
        "    Application if:\n",
        "      - explicit application keywords\n",
        "      - OR message contains any numeric field words (income/ltv/...) even without numbers\n",
        "      - OR message contains 2+ numbers (real user behavior)\n",
        "      - OR regex extraction finds at least one field value\n",
        "    \"\"\"\n",
        "    t = _norm_spaces(text)\n",
        "    if not t:\n",
        "        return False\n",
        "\n",
        "    if any(k in t for k in APPLICATION_KEYWORDS):\n",
        "        return True\n",
        "\n",
        "    # 2+ numbers usually means they are providing parameters\n",
        "    nums = re.findall(r\"\\d+(?:\\.\\d+)?\", t)\n",
        "    if len(nums) >= 2:\n",
        "        return True\n",
        "\n",
        "    # if they mention any required fields, treat as application\n",
        "    req = _req_safe()\n",
        "    if any(f.lower() in t for f in req):\n",
        "        return True\n",
        "\n",
        "    # mention of numeric signals is enough to treat as application conversation\n",
        "    if any(s in t for s in NUMERIC_SIGNALS):\n",
        "        return True\n",
        "\n",
        "    # last safety: if your extractor can pull something, it's application\n",
        "    try:\n",
        "        extracted = extract_fields_regex(text)  # type: ignore[name-defined]\n",
        "        if any(v is not None for v in extracted.values()):\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return False\n",
        "\n",
        "def route_intent(text: str) -> str:\n",
        "    t = _norm_spaces(text)\n",
        "\n",
        "    # concept wins first (but only loan-domain concepts)\n",
        "    if is_concept_question(t):\n",
        "        return \"concept\"\n",
        "\n",
        "    # application second\n",
        "    if looks_like_application(t):\n",
        "        return \"application\"\n",
        "\n",
        "    return \"out_of_scope\"\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# 2) Agent step (FINAL)\n",
        "# =========================================================\n",
        "\n",
        "def missing_fields(known: Dict[str, Any]) -> List[str]:\n",
        "    req = _req_safe()\n",
        "    return [f for f in req if known.get(f) is None]\n",
        "\n",
        "def _missing_question(state: Dict[str, Any], miss: List[str]) -> str:\n",
        "    cur = tuple(miss)\n",
        "    if state.get(\"last_missing\") == cur:\n",
        "        q = \"I still need the same missing fields. Please provide them in one message.\"\n",
        "    else:\n",
        "        q = \"Please provide: \" + \", \".join(miss)\n",
        "    state[\"last_missing\"] = cur\n",
        "    return q\n",
        "\n",
        "def _run_assessment_with_saved_fields(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    known = state[\"known_fields\"]\n",
        "\n",
        "    p_default = predict_default_probability(known)  # type: ignore[name-defined]\n",
        "    bucket = map_prob_to_bucket(p_default)          # type: ignore[name-defined]\n",
        "    offer = offer_engine(bucket)                   # type: ignore[name-defined]\n",
        "\n",
        "    policy_docs = rag_fetch(\"loan risk offer policy schema conditions catalog\", k=4)  # type: ignore[name-defined]\n",
        "    rag_sources = [d.metadata.get(\"source\", \"unknown\") for d in policy_docs]\n",
        "\n",
        "    expl = explanation_with_llm(p_default, bucket, offer, known, rag_sources)  # type: ignore[name-defined]\n",
        "\n",
        "    final_out = build_final_json(  # type: ignore[name-defined]\n",
        "        p_default=p_default,\n",
        "        bucket=bucket,\n",
        "        offer=offer,\n",
        "        known=known,\n",
        "        rag_sources=rag_sources,\n",
        "        explanation=expl,\n",
        "        missing=[]\n",
        "    )\n",
        "    return {\"type\": \"final_answer\", \"output\": final_out}\n",
        "\n",
        "def agent_step(user_text: str, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    state.setdefault(\"known_fields\", {})\n",
        "    state.setdefault(\"history\", [])\n",
        "    state.setdefault(\"last_missing\", None)\n",
        "\n",
        "    user_text = (user_text or \"\").strip()\n",
        "\n",
        "    # HARD OVERRIDE\n",
        "    if user_text == \"__RUN_ASSESSMENT__\":\n",
        "        miss = missing_fields(state[\"known_fields\"])\n",
        "        if miss:\n",
        "            q = _missing_question(state, miss)\n",
        "            state[\"history\"].append({\"role\": \"user\", \"text\": \"__RUN_ASSESSMENT__\"})\n",
        "            state[\"history\"].append({\"role\": \"assistant\", \"text\": q})\n",
        "            return {\"type\": \"missing_fields\", \"missing\": miss, \"question\": q, \"known_fields\": dict(state[\"known_fields\"])}\n",
        "\n",
        "        out = _run_assessment_with_saved_fields(state)\n",
        "        state[\"history\"].append({\"role\": \"user\", \"text\": \"__RUN_ASSESSMENT__\"})\n",
        "        state[\"history\"].append({\"role\": \"assistant\", \"text\": \"FINAL\"})\n",
        "        return out\n",
        "\n",
        "    # log user\n",
        "    state[\"history\"].append({\"role\": \"user\", \"text\": user_text})\n",
        "\n",
        "    intent = route_intent(user_text)\n",
        "\n",
        "    # CONCEPT\n",
        "    if intent == \"concept\":\n",
        "        out = concept_answer(user_text, k=4)  # type: ignore[name-defined]\n",
        "        state[\"history\"].append({\"role\": \"assistant\", \"text\": out.get(\"answer\", \"\")})\n",
        "        return out\n",
        "\n",
        "    # OUT OF SCOPE\n",
        "    if intent == \"out_of_scope\":\n",
        "        msg = \"I can help with loan risk concepts (e.g., LTV/DTI/DTIR1/credit score) or a loan application assessment. Please ask a loan-related question.\"\n",
        "        state[\"history\"].append({\"role\": \"assistant\", \"text\": msg})\n",
        "        return {\"type\": \"out_of_scope\", \"answer\": msg, \"sources\": []}\n",
        "\n",
        "    # APPLICATION\n",
        "    extracted = extract_fields_regex(user_text)  # type: ignore[name-defined]\n",
        "    state[\"known_fields\"].update({k: v for k, v in extracted.items() if v is not None})\n",
        "\n",
        "    miss = missing_fields(state[\"known_fields\"])\n",
        "    if miss:\n",
        "        q = _missing_question(state, miss)\n",
        "        state[\"history\"].append({\"role\": \"assistant\", \"text\": q})\n",
        "        return {\"type\": \"missing_fields\", \"missing\": miss, \"question\": q, \"known_fields\": dict(state[\"known_fields\"])}\n",
        "\n",
        "    out = _run_assessment_with_saved_fields(state)\n",
        "    state[\"history\"].append({\"role\": \"assistant\", \"text\": \"FINAL\"})\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "D4vyPekiQNUH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n"
      ],
      "metadata": {
        "id": "Nee6hW1sFpFH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "print(inspect.signature(build_final_json))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZKmD2KvcDo",
        "outputId": "cb3e1695-ab2d-49d0-869d-20bce6d60d97"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(p_default: float, bucket: str, offer: Dict[str, Any], known: Dict[str, Any], rag_sources: List[str], explanation: str, missing: List[str]) -> Dict[str, Any]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 13) Chat UI layer (Gradio) — \"the rest\"\n",
        "# - Keeps state across messages (does NOT forget values)\n",
        "# - After each message: asks ONLY remaining fields\n",
        "# - \"run assessment\" triggers __RUN_ASSESSMENT__ sentinel\n",
        "# - Concept questions are answered from concepts.json (via concept_answer)\n",
        "# - Out-of-scope questions return a clean message (no field loop)\n",
        "# =========================================================\n",
        "\n",
        "import gradio as gr\n",
        "import json\n",
        "import re\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "# -----------------------------\n",
        "# A) Small utilities (chat control + rendering)\n",
        "# -----------------------------\n",
        "EXIT_WORDS = {\"exit\", \"quit\", \"q\", \"stop\", \"end\"}\n",
        "SMALLTALK_PATTERNS = [\n",
        "    r\"\\b(thanks|thank you|thx|ty|merci|tnx|no thanks)\\b\",\n",
        "    r\"\\b(bye|goodbye|see you|cya)\\b\",\n",
        "    r\"\\b(hi|hello|hey|salam|سلام)\\b\",\n",
        "]\n",
        "\n",
        "def normalize_command(text: str) -> str:\n",
        "    \"\"\"Normalize common typos/variants so commands don't fall into the wrong branch.\"\"\"\n",
        "    t = (text or \"\").strip().lower()\n",
        "    t = t.replace(\"asseement\", \"assessment\")\n",
        "    t = t.replace(\"assesment\", \"assessment\")\n",
        "    t = t.replace(\"assessement\", \"assessment\")\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "def is_exit(text_norm: str) -> bool:\n",
        "    return (text_norm or \"\").strip().lower() in EXIT_WORDS\n",
        "\n",
        "def is_smalltalk(text: str) -> bool:\n",
        "    t = (text or \"\").strip().lower()\n",
        "    return any(re.search(p, t) for p in SMALLTALK_PATTERNS)\n",
        "\n",
        "def is_run_request(text_norm: str) -> bool:\n",
        "    t = (text_norm or \"\").strip().lower()\n",
        "    # explicit commands\n",
        "    if t in {\"run\", \"assess\", \"assessment\", \"rerun\", \"re-run\", \"run assessment\", \"run the assessment\"}:\n",
        "        return True\n",
        "    # loose match\n",
        "    return (\"run\" in t and \"assessment\" in t) or (t.startswith(\"run \") and \"assess\" in t)\n",
        "\n",
        "def safe_string(x) -> str:\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, str):\n",
        "        return x\n",
        "    try:\n",
        "        return json.dumps(x, ensure_ascii=False)\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "def render_final_output_as_sentences(output_dict: dict) -> str:\n",
        "    \"\"\"\n",
        "    Renders the final JSON into:\n",
        "    - explanation paragraph\n",
        "    - summary line\n",
        "    - collapsible technical JSON\n",
        "    \"\"\"\n",
        "    ra = output_dict.get(\"Risk_Assessment\", {}) or {}\n",
        "    off = output_dict.get(\"Offer\", {}) or {}\n",
        "    expl = output_dict.get(\"Explanation\", {}) or {}\n",
        "\n",
        "    paragraph = (expl.get(\"paragraph\", \"\") or \"\").strip()\n",
        "    bucket = ra.get(\"risk_bucket\", \"Unknown\")\n",
        "    p = ra.get(\"default_probability\", None)\n",
        "    p_txt = f\"{p:.2f}\" if isinstance(p, (int, float)) else \"N/A\"\n",
        "    decision = off.get(\"decision\", \"Unknown\")\n",
        "\n",
        "    if not paragraph:\n",
        "        paragraph = (\n",
        "            f\"Based on the provided information, the estimated default probability is about {p_txt} \"\n",
        "            f\"and the risk bucket is {bucket}. Recommended decision: {decision}.\"\n",
        "        )\n",
        "\n",
        "    summary = f\"Summary: decision={decision} | risk_bucket={bucket} | default_probability={p_txt}\"\n",
        "\n",
        "    details = (\n",
        "        \"<details><summary>Show technical JSON</summary>\\n\\n\"\n",
        "        f\"```json\\n{json.dumps(output_dict, indent=2, ensure_ascii=False)}\\n```\\n\"\n",
        "        \"</details>\"\n",
        "    )\n",
        "    return f\"{paragraph}\\n\\n{summary}\\n\\n{details}\"\n",
        "\n",
        "def smalltalk_reply(text: str, agent_state: dict) -> str:\n",
        "    t = (text or \"\").strip().lower()\n",
        "\n",
        "    # Keep it polite, do not corrupt state\n",
        "    if any(w in t for w in [\"thanks\", \"thank\", \"thx\", \"ty\", \"merci\", \"tnx\", \"no thanks\"]):\n",
        "        return \"You're welcome. You can continue the loan application or type 'run assessment' when ready.\"\n",
        "\n",
        "    if any(w in t for w in [\"bye\", \"goodbye\", \"cya\", \"see you\"]):\n",
        "        return \"Goodbye. You can continue later; your current session state remains unless you type 'exit' or press Reset.\"\n",
        "\n",
        "    return \"Hi. Ask a loan concept definition (e.g., DTIR1, LTV) or start an application (e.g., 'I want to apply for a loan').\"\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# B) Gradio chat function (stateful per session)\n",
        "# IMPORTANT: requires your agent_step() to be defined earlier (the code you already have)\n",
        "# -----------------------------\n",
        "def gradio_chat(user_message, chat_history, agent_state):\n",
        "    raw = (user_message or \"\").strip()\n",
        "    chat_history = chat_history or []\n",
        "\n",
        "    # Ensure state structure\n",
        "    agent_state = agent_state or {\"known_fields\": {}, \"history\": [], \"last_missing\": None}\n",
        "    agent_state.setdefault(\"known_fields\", {})\n",
        "    agent_state.setdefault(\"history\", [])\n",
        "    agent_state.setdefault(\"last_missing\", None)\n",
        "\n",
        "    if not raw:\n",
        "        return \"\", chat_history, agent_state\n",
        "\n",
        "    user_norm = normalize_command(raw)\n",
        "\n",
        "    # Exit -> clears state\n",
        "    if is_exit(user_norm):\n",
        "        agent_state = {\"known_fields\": {}, \"history\": [], \"last_missing\": None}\n",
        "        chat_history.append({\"role\": \"user\", \"content\": raw})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": \"Session ended. Cleared saved application info. Type 'hi' to start again.\"})\n",
        "        return \"\", chat_history, agent_state\n",
        "\n",
        "    # Small talk -> polite answer, no state change\n",
        "    if is_smalltalk(raw):\n",
        "        assistant_msg = smalltalk_reply(raw, agent_state)\n",
        "        chat_history.append({\"role\": \"user\", \"content\": raw})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "        return \"\", chat_history, agent_state\n",
        "\n",
        "    # Run assessment command -> sentinel (your agent_step handles it)\n",
        "    try:\n",
        "        if is_run_request(user_norm):\n",
        "            out = agent_step(\"__RUN_ASSESSMENT__\", agent_state)\n",
        "        else:\n",
        "            out = agent_step(raw, agent_state)\n",
        "\n",
        "        out_type = (out.get(\"type\", \"\") or \"\").strip()\n",
        "\n",
        "        if out_type == \"missing_fields\":\n",
        "            assistant_msg = safe_string(out.get(\"question\", \"Please provide the missing fields.\"))\n",
        "\n",
        "        elif out_type == \"rag_answer\":\n",
        "            ans = safe_string(out.get(\"answer\", \"\"))\n",
        "            sources = out.get(\"sources\", [])\n",
        "            if isinstance(sources, list) and sources:\n",
        "                assistant_msg = f\"{ans}\\n\\nSources: {', '.join(map(str, sources))}\"\n",
        "            else:\n",
        "                assistant_msg = ans\n",
        "\n",
        "        elif out_type == \"final_answer\":\n",
        "            output_dict = out.get(\"output\", {}) or {}\n",
        "            assistant_msg = render_final_output_as_sentences(output_dict)\n",
        "\n",
        "        elif out_type == \"out_of_scope\":\n",
        "            assistant_msg = safe_string(out.get(\"answer\", \"Out of scope.\"))\n",
        "\n",
        "        else:\n",
        "            assistant_msg = safe_string(out)\n",
        "\n",
        "    except Exception as e:\n",
        "        assistant_msg = f\"Internal error: {e}\"\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"content\": raw})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "    return \"\", chat_history, agent_state\n",
        "\n",
        "def reset_chat():\n",
        "    return \"\", [], {\"known_fields\": {}, \"history\": [], \"last_missing\": None}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# C) UI\n",
        "# -----------------------------\n",
        "with gr.Blocks(title=\"Loan Risk Agent Demo\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "# Loan Risk Assistant (Demo)\n",
        "\n",
        "**You can:**\n",
        "- Ask **definitions**: “What does DTIR1 mean?” “Define LTV”\n",
        "- Apply for a loan **step-by-step**: “I want to apply”, then send income, score, etc.\n",
        "- Or provide many fields in one message.\n",
        "- Type **run assessment** to force evaluation using saved fields.\n",
        "- Type **exit** to clear the session.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    chatbot = gr.Chatbot(height=420, type=\"messages\")\n",
        "    msg = gr.Textbox(placeholder=\"Type your message here...\", show_label=False)\n",
        "\n",
        "    state = gr.State({\"known_fields\": {}, \"history\": [], \"last_missing\": None})\n",
        "\n",
        "    with gr.Row():\n",
        "        send = gr.Button(\"Send\")\n",
        "        reset = gr.Button(\"Reset\")\n",
        "\n",
        "    send.click(gradio_chat, inputs=[msg, chatbot, state], outputs=[msg, chatbot, state])\n",
        "    msg.submit(gradio_chat, inputs=[msg, chatbot, state], outputs=[msg, chatbot, state])\n",
        "    reset.click(reset_chat, inputs=[], outputs=[msg, chatbot, state])\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "jKjyQWlyy8vo",
        "outputId": "e65965e3-738f-4531-b57a-71029edab18a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1751364341.py:195: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(height=420, type=\"messages\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ebda2284568c7ca4e1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ebda2284568c7ca4e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['age']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['age']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ebda2284568c7ca4e1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}